# Import libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt


# Download the Machine operating parameters
path = 'path_to_datafile.xlsx'
column_names = ['VI06273', 'KI06275','KI06276','VXI06253',
                'VYI06253', 'VXI06254', 'VYI06254', 'VXI06255', 'VYI06255',
                'VXI06256', 'VYI06256', 'ZI06272C',
                'PI00117', 'PI00121C', 'FI00124',
                'PDI00118', 'TI00116', 'TI00122', 'JI06003', 'II06003', 'EI06003',
                'VXI06252', 'VYI06252', 'VXI06251', 'VYI06251', 'ZI06271A']

# Import the dataset using pandas
#Determine the column names
raw_dataset = pd.read_excel(path, header=0, names=column_names, usecols = 'B,D:M,P,Q,T:AA,AC:AG',
                            na_filter=True, na_values='Bad Input', verbose=True)

# Remove NA rows from dataset 
raw_dataset = raw_dataset.dropna()

# Split the data into training and test sets
train_dataset = raw_dataset.sample(frac=0.90, random_state=1)
test_dataset = raw_dataset.drop(train_dataset.index)
train_features = train_dataset.copy()
test_features = test_dataset.copy()

# Define train and test labels
train_labels = train_features.pop('VI06273')
test_labels = test_features.pop('VI06273')

# Print(train_labels.tail())

# Create and train a Random Forest regression model
rf_model = RandomForestRegressor(n_estimators=50, criterion = 'friedman_mse',
                                 min_samples_split = 2, min_samples_leaf = 1,
                                 bootstrap=True, random_state=0)    
rf_model.fit(train_features, train_labels)

# Make predictions on the test set
vibr_predict = rf_model.predict(test_features)

# Evaluate the model' performance
score = rf_model.score(test_features, test_labels)
print(round(score, 3))

mse = mean_squared_error(test_labels, vibr_predict)
mae = mean_absolute_error(test_labels, vibr_predict)
r2 = r2_score(test_labels, vibr_predict)

print(f'Mean Squared Error (MSE): {round(mse, 3)}')
print(f'Mean Absolute Error (MAE): {round(mae, 3)}')
print(f'R-squared (R2): {round(r2,3)}')

# Get feature importances from the model
feature_importances = rf_model.feature_importances_

# Create a DataFrame to better visualize the importances
feature_importance_df = pd.DataFrame({'Feature': train_features.columns,
                                      'Importance': feature_importances})
feature_importance_df = feature_importance_df.sort_values(by='Importance',
                                                          ascending=False)

# Print the feature importances
print(feature_importance_df[['Feature','Importance']])

# Sort features by importance
feature_importance_df = feature_importance_df.sort_values('Importance')

# Plot the feature importances
plt.figure(figsize=(12, 8))
bars = plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], align = 'center', color = 'green')
plt.xlabel('Feature Importance')
plt.title('RandomForest Regression Model - Feature Importance')
plt.grid(True)

# Add feature importance values to the bars
for bar, importance in zip(bars, feature_importance_df['Importance']):
    plt.text(bar.get_width(), bar.get_y() + bar.get_height()/2, f'{importance:.3f}', va='center')

plt.show()
